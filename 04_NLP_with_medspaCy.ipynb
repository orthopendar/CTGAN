{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orthopendar/CTGAN/blob/main/04_NLP_with_medspaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65961103",
      "metadata": {
        "id": "65961103"
      },
      "source": [
        "\n",
        "<img src=\"https://github.com/abchapman93/DELPHI_Intro_to_NLP_Spring_2024/blob/main/media/DELPHI-long.png?raw=true\" size=\"20%\">\n",
        "</br>\n",
        "\n",
        "<h1 valign=\"center\" align=\"center\"><font size=\"+150\">Introduction to NLP in Python</br>Spring 2024</font></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c56389f-989e-4aaa-a460-1565e7b68fbe",
      "metadata": {
        "id": "7c56389f-989e-4aaa-a460-1565e7b68fbe"
      },
      "outputs": [],
      "source": [
        "!pip install https://github.com/abchapman93/DELPHI_Intro_to_NLP_Spring_2024/releases/download/v0.1/delphi_nlp_2024-0.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf956da3-d0fb-4ce9-9502-b9cdaf0cb770",
      "metadata": {
        "id": "bf956da3-d0fb-4ce9-9502-b9cdaf0cb770"
      },
      "outputs": [],
      "source": [
        "from delphi_nlp_2024 import *\n",
        "from delphi_nlp_2024.quizzes.quizzes import *\n",
        "from delphi_nlp_2024.helpers import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2208d3e3",
      "metadata": {
        "id": "2208d3e3"
      },
      "source": [
        "# NLP with medspaCy\n",
        "This notebook will introduce the Python package `medspaCy`, a toolkit for clinical NLP.\n",
        "\n",
        "# I. Overview\n",
        "Clinical text is very complex and differs from general domain language.\n",
        "- **It is very messy**, with semi-structured formatting from EHR\n",
        "- Clinical documents include **many abbreviations**, some of which are ambiguous\n",
        "- There are **specific tasks** needed in clinical NLP, such as **detecting negation or uncertainty** for concepts in the text\n",
        "\n",
        "## medspacy\n",
        "<img alt=\"MedSpaCy logo\" src=\"https://github.com/medspacy/medspacy/raw/master/images/medspacy_logo.png\">\n",
        "\n",
        "\n",
        "[Medspacy](https://github.com/medspacy/medspacy) is an open-source package maintained by NLP developers at the University of Utah and the US Department of Veterans Affairs. It's built using the popular [spaCy](https://spacy.io/) library and is specifically designed for working with clinical notes.\n",
        "\n",
        "The goal of medSpaCy is to provide flexible, easy-to-use spaCy components for common clinical NLP tasks, such as:\n",
        "\n",
        "- Concept extraction\n",
        "- Negation detection\n",
        "- Document section splitting\n",
        "\n",
        "Here are a couple of papers that used medspaCy:\n",
        "\n",
        "- [Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python\n",
        "](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8861690/)\n",
        "- [A Natural Language Processing System for National\n",
        "COVID-19 Surveillance in the US Department of Veterans Affairs](https://aclanthology.org/2020.nlpcovid19-acl.10.pdf)\n",
        "- [ReHouSED: A novel measurement of Veteran housing stability using natural language processing](https://www.sciencedirect.com/science/article/pii/S153204642100232X?via%3Dihub)\n",
        "- [Temporary Financial Assistance Reduced The Probability Of Unstable Housing Among Veterans For More Than 1 Year](https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2023.00730)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa470e87",
      "metadata": {
        "id": "aa470e87"
      },
      "source": [
        "## Getting started with medspaCy\n",
        "This notebook will walk show how to use medspaCy to process clinical text and introduce some of the spaCy infrastrcuture. We'll then design some rules to extract concepts from clinical texts.\n",
        "\n",
        "\n",
        "To get started with medspaCy, we'll import the library and then load a **model** which we will call `nlp`. A model in spaCy is the object which processes a note and performs the various steps of text processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86395d0-ae79-41d8-a000-aa2616054e65",
      "metadata": {
        "id": "b86395d0-ae79-41d8-a000-aa2616054e65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66d1ddf-e2b8-4d38-ec37-92eab79cad58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for unqlite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unqlite: filename=unqlite-0.9.6-cp310-cp310-linux_x86_64.whl size=1622755 sha256=13c1357188a02a5669ad5be038f5636a0f8a62e63872c810632397ed52d08c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f4/a1/7e97f75c3102460c515a52f33cd7d5d61a93a57408fd0efad8\n",
            "Successfully built medspacy unqlite\n",
            "Installing collected packages: pysimstring, unidecode, pysbd, pydantic, pathlib-abc, Cython, unqlite, quicksectx, pathy, thinc, PyFastNER, spacy, PyRuSH, medspacy-quickumls, medspacy\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.9\n",
            "    Uninstalling Cython-3.0.9:\n",
            "      Successfully uninstalled Cython-3.0.9\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.3\n",
            "    Uninstalling thinc-8.2.3:\n",
            "      Successfully uninstalled thinc-8.2.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.4\n",
            "    Uninstalling spacy-3.7.4:\n",
            "      Successfully uninstalled spacy-3.7.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-0.29.37 PyFastNER-1.0.10 PyRuSH-1.0.8 medspacy-1.1.5 medspacy-quickumls-3.0 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.10.14 pysbd-0.3.4 pysimstring-1.2.1 quicksectx-0.3.9 spacy-3.5.4 thinc-8.1.12 unidecode-1.3.8 unqlite-0.9.6\n"
          ]
        }
      ],
      "source": [
        "!pip install medspacy==1.1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256d0929",
      "metadata": {
        "id": "256d0929"
      },
      "outputs": [],
      "source": [
        "import medspacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3b4566",
      "metadata": {
        "id": "6c3b4566"
      },
      "source": [
        "### `nlp`\n",
        "The simplest way to create a model in medspaCy is `medspaCy.load()`. This is a spaCy `English` class. You can also load models for other languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a9f92e",
      "metadata": {
        "id": "46a9f92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85661de2-6773-42f6-cc4b-0b77240f7956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7ab5c0089270>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nlp = medspacy.load()\n",
        "nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00712877",
      "metadata": {
        "id": "00712877"
      },
      "source": [
        "### `Doc`\n",
        "To process a text, we call `nlp(text)` and save the result to `doc`. Calling `nlp` on a text returns an object from the `Doc` class. In spaCy, `Doc` objects represent a single text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa679ab",
      "metadata": {
        "id": "3aa679ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567d82a8-cb09-40a6-da8e-ae7ee2dacbcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chief complaint: Fever and SOB"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "text = \"Chief complaint: Fever and SOB\"\n",
        "doc = nlp(text)\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f81ec64",
      "metadata": {
        "id": "7f81ec64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8630b22-85a1-4531-c625-20d0602bf856"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb614b58",
      "metadata": {
        "id": "cb614b58"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "df22bad5",
      "metadata": {
        "id": "df22bad5"
      },
      "source": [
        "### `Token`\n",
        "A `Token` is a single word, symbol, or whitespace in a `doc`. When we create a `doc` object, the text broken up into individual tokens. This is called **\"tokenization\"**.\n",
        "\n",
        "**Discussion**: Look at the tokens generated from this text snippet. What can you say about the tokenization method? Is it as simple as splitting up into words every time we reach a whitespace?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a97bf46",
      "metadata": {
        "id": "6a97bf46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f1ea26-d45b-46d9-b9d9-221f6c8637ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chief\n",
            "complaint\n",
            ":\n",
            "Fever\n",
            "and\n",
            "SOB\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abe352e",
      "metadata": {
        "id": "2abe352e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6272fdd-d90f-40b5-ce73-a24a535843cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.token.Token'>\n"
          ]
        }
      ],
      "source": [
        "print(type(token))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f5944c",
      "metadata": {
        "id": "74f5944c"
      },
      "source": [
        "If we access a single index of a doc, we get a token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ce2401",
      "metadata": {
        "id": "e1ce2401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241c4d2a-09df-402f-8ba1-0494f6986c22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chief"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "token = doc[0]\n",
        "token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30593c3",
      "metadata": {
        "id": "b30593c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "1ece474e-b4c3-4b22-ab4b-db0644895454"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'quiz_doc_cc_idx' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9388f55c4899>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquiz_doc_cc_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'quiz_doc_cc_idx' is not defined"
          ]
        }
      ],
      "source": [
        "quiz_doc_cc_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed548101",
      "metadata": {
        "id": "ed548101"
      },
      "source": [
        "### `Span`\n",
        "While a `Token` represents a single word, a `Span` represents one or more words from a `Doc`. We can get a `Span` by slicing a `Doc` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6924b484",
      "metadata": {
        "id": "6924b484"
      },
      "outputs": [],
      "source": [
        "span = doc[0:3]\n",
        "span"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79c1b0ad",
      "metadata": {
        "id": "79c1b0ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "283be07a",
      "metadata": {
        "id": "283be07a"
      },
      "source": [
        "## Pipeline Components\n",
        "Under the hood, the `nlp` object goes through a number of sequential steps to process the text. This is called a **pipeline** and it allows us to create modular, independent processing steps when analyzing text. We can see the names of our pipeline components through the `nlp.pipe_names` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca111cc",
      "metadata": {
        "id": "0ca111cc"
      },
      "outputs": [],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23ab0c5e",
      "metadata": {
        "id": "23ab0c5e"
      },
      "source": [
        "There's also a hidden component which runs before all of them called the `tokenizer`. This splits text up into tokens and creates a `Doc` object, which is then passed on to the rest of the components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007105a5",
      "metadata": {
        "id": "007105a5"
      },
      "outputs": [],
      "source": [
        "nlp.tokenizer(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842bcbf4",
      "metadata": {
        "id": "842bcbf4"
      },
      "source": [
        "We'll learn more about some of these pipeline components in the following notebooks. First, we'll start with the `target_matcher` component and learn how to extract clinical concepts from text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08b41bd",
      "metadata": {
        "id": "b08b41bd"
      },
      "outputs": [],
      "source": [
        "# For now, remove some components we don't need\n",
        "nlp.remove_pipe(\"medspacy_pyrush\")\n",
        "nlp.remove_pipe(\"medspacy_context\")\n",
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5130551b",
      "metadata": {
        "id": "5130551b"
      },
      "source": [
        "## Concept Extraction\n",
        "One of the first step in many clinical NLP tasks is identiyfing particular **concepts** in text. These will vary in each use case, but some common examples of concepts are:\n",
        "- Diagnoses\n",
        "- Signs and symptoms\n",
        "- Medications\n",
        "- Tests\n",
        "\n",
        "### TODO\n",
        "For each of the texts below, identify the best description of the concepts **in bold**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1feace",
      "metadata": {
        "id": "4c1feace"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TO SEE QUIZ\n",
        "quiz_medical_concepts_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933f9545",
      "metadata": {
        "id": "933f9545"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TO SEE QUIZ\n",
        "quiz_medical_concepts_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09062bb2",
      "metadata": {
        "id": "09062bb2"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TO SEE QUIZ\n",
        "quiz_medical_concepts_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c8f51a",
      "metadata": {
        "id": "e5c8f51a"
      },
      "source": [
        "The task of extracting these spans of text is called **named entity recognition (NER)**. This can be done using either machine learning models or rule-based models. In this class, we'll focus on building rule-based systems. In rule-based NLP, we define patterns to match concepts in text. SpaCy offers many [rule-based methods](https://spacy.io/usage/rule-based-matching). MedSpaCy uses a pipeline component called `TargetMatcher` and rules defined by a class called `TargetRule`. Extracted concepts will be stored as `Span` objects in `doc.ents`.\n",
        "\n",
        "### `target_matcher`\n",
        "To start adding rules, we'll first need to access the pipeline component. We can do this by calling `nlp.get_pipe(pipe_name)`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d92aad4",
      "metadata": {
        "id": "0d92aad4"
      },
      "outputs": [],
      "source": [
        "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7b38b0",
      "metadata": {
        "id": "5f7b38b0"
      },
      "source": [
        "Next we need to actually write some rules using the `TargetRule` class. Target rules require two positional arguments:\n",
        "- `literal`: A span of text to match in the text (case insensitive)\n",
        "- `category`: The label to assign to extracted concepts\n",
        "\n",
        "(There are also a few keyword arguments that we'll explore later, but these are the two required arguments.)\n",
        "\n",
        "Let's say that we want to extract patient diagnoses from the following text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47394118",
      "metadata": {
        "id": "47394118"
      },
      "outputs": [],
      "source": [
        "dx_text = \"Pt is a 63M w/ h/o metastatic carcinoid tumor, HTN and hyperlipidemia\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b4b00c",
      "metadata": {
        "id": "30b4b00c"
      },
      "source": [
        "There are three diagnoses in this text. The first is `\"metastatic carcinoid tumor\"`. Let's write a rule to capture this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bddb2ec",
      "metadata": {
        "id": "6bddb2ec"
      },
      "outputs": [],
      "source": [
        "from medspacy.target_matcher import TargetRule\n",
        "rule = TargetRule(\"metastatic carcinoid tumor\", \"DIAGNOSIS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f8d7d5b",
      "metadata": {
        "id": "8f8d7d5b"
      },
      "source": [
        "We can then add it to our target matcher:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff5fa0a",
      "metadata": {
        "id": "cff5fa0a"
      },
      "outputs": [],
      "source": [
        "target_matcher.add(rule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbf25b5",
      "metadata": {
        "id": "5dbf25b5"
      },
      "outputs": [],
      "source": [
        "target_matcher.rules"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c74daa",
      "metadata": {
        "id": "79c74daa"
      },
      "source": [
        "Now let's process the text above and see if it's extracted by our NLP model by looking at `doc.ents`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebfe523",
      "metadata": {
        "id": "9ebfe523"
      },
      "outputs": [],
      "source": [
        "doc = nlp(dx_text)\n",
        "doc.ents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951835d6",
      "metadata": {
        "id": "951835d6"
      },
      "source": [
        "The `target_matcher` added a `Span` to the doc's entities representing the concept we just extracted. Let's assign this span to the variable `ent`. We can see the concept category by checking the `ent.label_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ae08e4",
      "metadata": {
        "id": "b8ae08e4"
      },
      "outputs": [],
      "source": [
        "ent = doc.ents[0]\n",
        "print(ent)\n",
        "print(type(ent))\n",
        "print(ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8668a612",
      "metadata": {
        "id": "8668a612"
      },
      "source": [
        "`medspaCy` provides some visualization functions which make it easier to look at what has been extracted from the notes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a504b0",
      "metadata": {
        "id": "08a504b0"
      },
      "outputs": [],
      "source": [
        "from medspacy.visualization import visualize_ent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9420bf",
      "metadata": {
        "id": "2d9420bf"
      },
      "outputs": [],
      "source": [
        "visualize_ent(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397c847a",
      "metadata": {
        "id": "397c847a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a6a3fb24",
      "metadata": {
        "id": "a6a3fb24"
      },
      "source": [
        "### TODO\n",
        "Edit the cell below to write a list of rules for extracting the two remaining diagnoses from `dx_text`. Then add them to the target matcher and reprocess the doc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6dbf9b",
      "metadata": {
        "id": "aa6dbf9b"
      },
      "outputs": [],
      "source": [
        "rules = [\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5871d3b4",
      "metadata": {
        "id": "5871d3b4"
      },
      "outputs": [],
      "source": [
        "target_matcher.add(rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109e6292",
      "metadata": {
        "id": "109e6292"
      },
      "outputs": [],
      "source": [
        "doc_dx = nlp(dx_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd99107d",
      "metadata": {
        "id": "cd99107d"
      },
      "outputs": [],
      "source": [
        "visualize_ent(doc_dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42fead68",
      "metadata": {
        "id": "42fead68"
      },
      "outputs": [],
      "source": [
        "doc_dx.ents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ef663b",
      "metadata": {
        "id": "75ef663b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3755f5",
      "metadata": {
        "id": "6a3755f5"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TO TEST VALUE\n",
        "test_dx_text.test(doc_dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2f25ac",
      "metadata": {
        "id": "ea2f25ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c4c818a0",
      "metadata": {
        "id": "c4c818a0"
      },
      "source": [
        "### Advanced pattern matching\n",
        "We could pass in simple strings to our `ruler` to extract exact matches. However, there may be lots of small variations in the text we want to extract, and it will grow cumbersome to type out every single possible string. Instead, we'll do some more advanced matching by using **token attribute matching**.\n",
        "\n",
        "SpaCy allows us to write patterns based on not only the exact text, but other linguistic attributes such as **part-of-speech tag**, **numerical properties**, **regular expressions**, and much more.\n",
        "\n",
        "### Example: Chronic Kidney Disease\n",
        "Each of the texts below mention a different stage of Chronic Kidney Disease:\n",
        "\n",
        "---\n",
        "- 76 year old man with CKD Stage 3.\n",
        "- relevant diagnoses: ckd stage 4\n",
        "- The patient has progressed to ckd stage 5\n",
        "---\n",
        "\n",
        "We could write different target rules to match each text, but sometimes there are too many combinations to feasibly write out every option. Instead of trying to think of the near-infinite number of variations, let's write one pattern which will match all of these clinical problems.\n",
        "\n",
        "One way we can do this using **regular expressions**. We can pass a regular expression into the `pattern` argument for a TargetRule. The pattern will be case insensitive.\n",
        "\n",
        "#### TODO\n",
        "Finish the code below to create a rule matching which will match all three examples of CKD using regular expressions. Then add it to the pipeline and test your model. You can test it on the three examples below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4ec6c0",
      "metadata": {
        "id": "fc4ec6c0"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"76 year old man with CKD Stage 3.\",\n",
        "    \"relevant diagnoses: ckd stage 4\",\n",
        "    \"The patient has progressed to ckd stage 5\",\n",
        "    \"She was dx'd with CKD in January.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525f0de8",
      "metadata": {
        "id": "525f0de8"
      },
      "outputs": [],
      "source": [
        "rule = TargetRule(\"CKD Stage X\", \"DIAGNOSIS\",\n",
        "                  pattern=___)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43e13fa",
      "metadata": {
        "id": "e43e13fa"
      },
      "outputs": [],
      "source": [
        "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
        "target_matcher.add(rule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86075d7",
      "metadata": {
        "id": "a86075d7"
      },
      "outputs": [],
      "source": [
        "for text in texts:\n",
        "    visualize_ent(nlp(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5118a193",
      "metadata": {
        "id": "5118a193"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4aab8e",
      "metadata": {
        "id": "fa4aab8e"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TEST VALUE\n",
        "test_ckd_stage_x.test(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111cd8b5",
      "metadata": {
        "id": "111cd8b5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ea1f92fa",
      "metadata": {
        "id": "ea1f92fa"
      },
      "source": [
        "## Concept extraction practice\n",
        "Let's return to the example discharge summary we looked at in a previous notebook. Add rules to `target_matcher` that will extract the following concepts from the text:\n",
        "- `\"DIAGNOSIS\"`\n",
        "- `\"MEDICATION\"`\n",
        "- `\"SIGN/SYMPTOM\"`\n",
        "- `\"SOCIAL_DETERMINANT\"`\n",
        "- `\"PROCEDURE\"`\n",
        "\n",
        "It might be useful to work in teams with clinicians or people familiar with these concepts so you can identify and define them. You don't need to extract every concept from the text (there are a lot!) so maybe just go through the note and add a few examples of each conceptt. If you'd like to write more sophisticated rules, it may be helpful to review spaCy's [rule-based NLP documentation](https://spacy.io/usage/rule-based-matching#matcher) (look at the documentation under `Matcher`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c232c8a",
      "metadata": {
        "id": "5c232c8a"
      },
      "outputs": [],
      "source": [
        "# RUN CELL TO SEE HINT\n",
        "hint_discharge_summ_target_rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4872d16",
      "metadata": {
        "id": "e4872d16"
      },
      "outputs": [],
      "source": [
        "# Load a fresh NLP model\n",
        "nlp = medspacy.load(enable=[\"medspacy_target_matcher\"])\n",
        "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e79e2b5",
      "metadata": {
        "id": "8e79e2b5"
      },
      "outputs": [],
      "source": [
        "rules = [\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "target_matcher.add(rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236c9efc",
      "metadata": {
        "id": "236c9efc"
      },
      "outputs": [],
      "source": [
        "doc = nlp(disch_summ)\n",
        "visualize_ent(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbdb6a7",
      "metadata": {
        "id": "dfbdb6a7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}